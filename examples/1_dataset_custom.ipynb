{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ns1254/miniforge3/envs/lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import imageio\n",
    "import torch\n",
    "\n",
    "import lerobot\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo_id = \"lerobot/pusht\" \n",
    "# dataset = LeRobotDataset(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/home/ns1254/lerobot/lerobot/common/datasets/push_dataset_to_hub/')\n",
    "\n",
    "from aloha_hdf5_format import from_raw_to_lerobot_format\n",
    "\n",
    "raw_dir = Path(\"/home/ns1254/act/dataset\")\n",
    "hf_dataset, episode_data_index, info = from_raw_to_lerobot_format(raw_dir, None, 20, False)\n",
    "dataset=LeRobotDataset.from_preloaded(LeRobotDataset, hf_dataset=hf_dataset, episode_data_index=episode_data_index, info=info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeRobotDataset(\n",
      "  Repository ID: '<class 'lerobot.common.datasets.lerobot_dataset.LeRobotDataset'>',\n",
      "  Split: 'train',\n",
      "  Number of Samples: 20000,\n",
      "  Number of Episodes: 50,\n",
      "  Type: image (.png),\n",
      "  Recorded Frames per Second: 20,\n",
      "  Camera Keys: ['observation.images.top'],\n",
      "  Video Frame Keys: N/A,\n",
      "  Transformations: None,\n",
      "  Codebase Version: v1.6,\n",
      ")\n",
      "Dataset({\n",
      "    features: ['observation.images.top', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.done', 'index'],\n",
      "    num_rows: 20000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset.hf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "average number of frames per episode: 400.000\n",
      "frames per second used during data collection: dataset.fps=20\n",
      "keys to access images from cameras: dataset.camera_keys=['observation.images.top']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\naverage number of frames per episode: {dataset.num_samples / dataset.num_episodes:.3f}\")\n",
    "print(f\"frames per second used during data collection: {dataset.fps=}\")\n",
    "print(f\"keys to access images from cameras: {dataset.camera_keys=}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to disk\n",
    "dataset_path = Path(\"/home/ns1254/lerobot/dataset/custom\")\n",
    "# dataset.save(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(dataset)\n",
    "# dataset.save_to_disk(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dataset, dataset_path / \"dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds= torch.load(dataset_path / \"dataset.pt\")\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (2/2 shards): 100%|██████████| 20000/20000 [00:00<00:00, 28408.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset = dataset.hf_dataset.with_format(None)  # to remove transforms that cant be saved\n",
    "hf_dataset.save_to_disk(dataset_path  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeRobotDataset(\n",
       "  Repository ID: '<class 'lerobot.common.datasets.lerobot_dataset.LeRobotDataset'>',\n",
       "  Split: 'train',\n",
       "  Number of Samples: 20000,\n",
       "  Number of Episodes: 50,\n",
       "  Type: image (.png),\n",
       "  Recorded Frames per Second: 20,\n",
       "  Camera Keys: ['observation.images.top'],\n",
       "  Video Frame Keys: N/A,\n",
       "  Transformations: None,\n",
       "  Codebase Version: v1.6,\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.datasets.populate_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_lerobot_dataset_on_disk(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats = compute_stats(lerobot_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (2/2 shards): 100%|██████████| 20000/20000 [00:00<00:00, 28445.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "lerobot_dataset=dataset\n",
    "hf_dataset = lerobot_dataset.hf_dataset\n",
    "info = lerobot_dataset.info\n",
    "stats = lerobot_dataset.stats\n",
    "episode_data_index = lerobot_dataset.episode_data_index\n",
    "# local_dir = lerobot_dataset.videos_dir.parent\n",
    "local_dir  = Path(\"/home/ns1254/lerobot/dataset/custom2\")\n",
    "meta_data_dir = local_dir / \"meta_data\"\n",
    "\n",
    "hf_dataset = hf_dataset.with_format(None)  # to remove transforms that cant be saved\n",
    "hf_dataset.save_to_disk(str(local_dir / \"train\"))\n",
    "\n",
    "if stats==None: \n",
    "    stats={}\n",
    "save_meta_data(info, stats, episode_data_index, meta_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access frame indexes associated to first episode\n",
    "episode_index = 0\n",
    "from_idx = dataset.episode_data_index[\"from\"][episode_index].item()\n",
    "to_idx = dataset.episode_data_index[\"to\"][episode_index].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LeRobot datasets actually subclass PyTorch datasets so you can do everything you know and love from working\n",
    "# with the latter, like iterating through the dataset. Here we grab all the image frames.\n",
    "frames = [dataset[idx][\"observation.images.top\"] for idx in range(from_idx, to_idx)]\n",
    "\n",
    "# Video frames are now float32 in range [0,1] channel first (c,h,w) to follow pytorch convention. To visualize\n",
    "# them, we convert to uint8 in range [0,255]\n",
    "frames = [(frame * 255).type(torch.uint8) for frame in frames]\n",
    "# and to channel last (h,w,c).\n",
    "frames = [frame.permute((1, 2, 0)).numpy() for frame in frames]\n",
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Finally, we save the frames to a mp4 video for visualization.\n",
    "Path(\"outputs/examples/1_load_lerobot_dataset\").mkdir(parents=True, exist_ok=True)\n",
    "imageio.mimsave(\"outputs/examples/1_load_lerobot_dataset/episode_0_custom_act.mp4\", frames, fps=dataset.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset[0]['observation.images.top'].shape=torch.Size([4, 3, 480, 640])\n",
      "dataset[0]['observation.state'].shape=torch.Size([8, 14])\n",
      "dataset[0]['action'].shape=torch.Size([64, 14])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For many machine learning applications we need to load the history of past observations or trajectories of\n",
    "# future actions. Our datasets can load previous and future frames for each key/modality, using timestamps\n",
    "# differences with the current loaded frame. For instance:\n",
    "delta_timestamps = {\n",
    "    # loads 4 images: 1 second before current frame, 500 ms before, 200 ms before, and current frame\n",
    "    \"observation.images.top\": [-1, -0.5, -0.20, 0],\n",
    "    # loads 8 state vectors: 1.5 seconds before, 1 second before, ... 20 ms, 10 ms, and current frame\n",
    "    \"observation.state\": [-1.5, -1, -0.5, -0.20, -0.10, -0.02, -0.01, 0],\n",
    "    # loads 64 action vectors: current frame, 1 frame in the future, 2 frames, ... 63 frames in the future\n",
    "    \"action\": [t / dataset.fps for t in range(64)],\n",
    "}\n",
    "# dataset = LeRobotDataset(repo_id, delta_timestamps=delta_timestamps)\n",
    "dataset=LeRobotDataset.from_preloaded(LeRobotDataset, hf_dataset=hf_dataset, episode_data_index=episode_data_index, info=info, delta_timestamps=delta_timestamps)\n",
    "\n",
    "print(f\"\\n{dataset[0]['observation.images.top'].shape=}\")  # (4,c,h,w)\n",
    "print(f\"{dataset[0]['observation.state'].shape=}\")  # (8,c)\n",
    "print(f\"{dataset[0]['action'].shape=}\\n\")  # (64,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, our datasets are fully compatible with PyTorch dataloaders and samplers because they are just\n",
    "# PyTorch datasets.\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=0,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch['observation.images.top'].shape=torch.Size([32, 4, 3, 480, 640])\n",
      "batch['observation.state'].shape=torch.Size([32, 8, 14])\n",
      "batch['action'].shape=torch.Size([32, 64, 14])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(f\"{batch['observation.images.top'].shape=}\")  # (32,4,c,h,w)\n",
    "    print(f\"{batch['observation.state'].shape=}\")  # (32,8,c)\n",
    "    print(f\"{batch['action'].shape=}\")  # (32,64,c)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['observation.images.top', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.done', 'index', 'observation.images.top_is_pad', 'observation.state_is_pad', 'action_is_pad'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (2/2 shards): 100%|██████████| 20000/20000 [00:00<00:00, 28045.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "local_dir = \"/home/ns1254/lerobot/dataset/act\"\n",
    "hf_dataset = hf_dataset.with_format(None)  # to remove transforms that cant be saved\n",
    "hf_dataset.save_to_disk(local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
