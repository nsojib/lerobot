{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ns1254/miniforge3/envs/lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ns1254/lerobot/lerobot/common/policies/vqbet/vqbet_utils.py:1385: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright 2024 The HuggingFace Inc. team. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import logging\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from contextlib import nullcontext\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from pprint import pformat\n",
    "from threading import Lock\n",
    "\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "from deepdiff import DeepDiff\n",
    "from omegaconf import DictConfig, ListConfig, OmegaConf\n",
    "from termcolor import colored\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "from lerobot.common.datasets.factory import make_dataset, resolve_delta_timestamps\n",
    "from lerobot.common.datasets.lerobot_dataset import MultiLeRobotDataset\n",
    "from lerobot.common.datasets.online_buffer import OnlineBuffer, compute_sampler_weights\n",
    "from lerobot.common.datasets.sampler import EpisodeAwareSampler\n",
    "from lerobot.common.datasets.utils import cycle\n",
    "from lerobot.common.envs.factory import make_env\n",
    "from lerobot.common.logger import Logger, log_output_dir\n",
    "from lerobot.common.policies.factory import make_policy\n",
    "from lerobot.common.policies.policy_protocol import PolicyWithUpdate\n",
    "from lerobot.common.policies.utils import get_device_from_parameters\n",
    "from lerobot.common.utils.utils import (\n",
    "    format_big_number,\n",
    "    get_safe_torch_device,\n",
    "    init_hydra_config,\n",
    "    init_logging,\n",
    "    set_global_seed,\n",
    ")\n",
    "from lerobot.scripts.eval import eval_policy\n",
    "from lerobot.common.policies.vqbet.modeling_vqbet import VQBeTOptimizer, VQBeTScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3365251/3074403060.py:7: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=config_path)\n"
     ]
    }
   ],
   "source": [
    "config_name=\"default\"\n",
    "config_path=\"../configs\"\n",
    "\n",
    "\n",
    "from hydra import compose, initialize\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path=config_path)  \n",
    "cfg = compose(config_name=config_name, overrides=[\"policy=vqbet\", \"env=pusht\", \"dataset_repo_id=lerobot/pusht\", \"device=cuda\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_env = make_env(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_safe_torch_device(cfg.device, log=True)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(cfg.seed) \n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 212 files: 100%|██████████| 212/212 [00:00<00:00, 196593.51it/s]\n"
     ]
    }
   ],
   "source": [
    "offline_dataset = make_dataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeRobotDataset(\n",
       "  Repository ID: 'lerobot/pusht',\n",
       "  Split: 'train',\n",
       "  Number of Samples: 25650,\n",
       "  Number of Episodes: 206,\n",
       "  Type: video (.mp4),\n",
       "  Recorded Frames per Second: 10,\n",
       "  Camera Keys: ['observation.image'],\n",
       "  Video Frame Keys: ['observation.image'],\n",
       "  Transformations: None,\n",
       "  Codebase Version: v1.6,\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation.image': [-0.4, -0.3, -0.2, -0.1, 0.0], 'observation.state': [-0.4, -0.3, -0.2, -0.1, 0.0], 'action': [-0.4, -0.3, -0.2, -0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.training.get(\"delta_timestamps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "sampler = None\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    offline_dataset,\n",
    "    num_workers=cfg.training.num_workers,\n",
    "    batch_size=cfg.training.batch_size,\n",
    "    shuffle=shuffle,\n",
    "    sampler=sampler,\n",
    "    pin_memory=device.type != \"cpu\",\n",
    "    drop_last=False,\n",
    ")\n",
    "dl_iter = cycle(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['observation.image', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.reward', 'next.done', 'next.success', 'index', 'observation.image_is_pad', 'observation.state_is_pad', 'action_is_pad'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(dl_iter)\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 5, 3, 96, 96]), torch.Size([64, 15, 2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['observation.image'].shape, batch['action'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 26.00M\n"
     ]
    }
   ],
   "source": [
    "policy = make_policy(\n",
    "    hydra_cfg=cfg,\n",
    "    dataset_stats=offline_dataset.stats if not cfg.resume else None,\n",
    "    pretrained_policy_name_or_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3365251/457647575.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  grad_scaler = GradScaler(enabled=cfg.use_amp)\n"
     ]
    }
   ],
   "source": [
    "optimizer = VQBeTOptimizer(policy, cfg)\n",
    "lr_scheduler = VQBeTScheduler(optimizer, cfg) \n",
    "grad_scaler = GradScaler(enabled=cfg.use_amp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dl_iter) \n",
    "for key in batch:\n",
    "    batch[key] = batch[key].to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_info = update_policy(\n",
    "#     policy,\n",
    "#     batch,\n",
    "#     optimizer,\n",
    "#     cfg.training.grad_clip_norm,\n",
    "#     grad_scaler=grad_scaler,\n",
    "#     lr_scheduler=lr_scheduler,\n",
    "#     use_amp=cfg.use_amp,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'n_different_codes', 'n_different_combinations', 'recon_l1_error'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict = policy.forward(batch)\n",
    "output_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
