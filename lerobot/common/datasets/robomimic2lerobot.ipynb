{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from datasets import Dataset, Features, Image, Sequence, Value\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "from lerobot.common.datasets.lerobot_dataset import CODEBASE_VERSION\n",
    "from lerobot.common.datasets.push_dataset_to_hub.utils import (\n",
    "    concatenate_episodes,\n",
    "    get_default_encoding,\n",
    "    save_images_concurrently,\n",
    ")\n",
    "from lerobot.common.datasets.utils import (\n",
    "    calculate_episode_data_index,\n",
    "    hf_transform_to_torch,\n",
    ")\n",
    "from lerobot.common.datasets.video_utils import VideoFrame, encode_video_frames\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf5_path = \"/home/ns1254/data_robomimic/nn/lift_image_v141_20p_abs.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = h5py.File(hdf5_path, \"r\")\n",
    "# demos = list(f[\"data\"].keys())\n",
    "\n",
    "# lengths=[]\n",
    "# for demo_name in demos:\n",
    "#     demo=f['data'][demo_name]\n",
    "#     num_samples=demo.attrs['num_samples']\n",
    "#     lengths.append(num_samples)\n",
    "\n",
    "# lengths=np.array(lengths)\n",
    "\n",
    "# print('Number of demos: ', len(demos))\n",
    "# print('Max length: ', np.max(lengths))\n",
    "# print('Min length: ', np.min(lengths))\n",
    "# print('Mean length: ', np.mean(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo=f['data'][demos[0]]\n",
    "# actions=demo['actions']\n",
    "# actions=np.array(actions)\n",
    "# demo['obs'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_keys=['actions', 'dones', 'rewards', 'states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_keys = [key for key in demo['obs'].keys()]\n",
    "# obs_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_keys_images=[key for key in obs_keys if 'image' in key]\n",
    "# obs_keys_others=[key for key in obs_keys if 'image' not in key]\n",
    "# obs_keys_images, obs_keys_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robomimic_to_hf_dataset(data_dict, video) -> Dataset:\n",
    "    features = {} \n",
    "\n",
    "    keys = [key for key in data_dict if \"observation.images.\" in key]\n",
    "    for key in keys:\n",
    "        if video:\n",
    "            features[key] = VideoFrame()\n",
    "        else:\n",
    "            features[key] = Image()\n",
    "            \n",
    "    for key in data_dict.keys():\n",
    "        if 'observation.' in key and 'images' not in key:\n",
    "            features[key] = Sequence(length=data_dict[key].shape[1], feature=Value(dtype=\"float32\", id=None))\n",
    "\n",
    "    features[\"action\"] = Sequence(length=data_dict[\"action\"].shape[1], feature=Value(dtype=\"float32\", id=None))\n",
    "    features[\"episode_index\"] = Value(dtype=\"int64\", id=None)\n",
    "    features[\"frame_index\"] = Value(dtype=\"int64\", id=None)\n",
    "    features[\"timestamp\"] = Value(dtype=\"float32\", id=None)\n",
    "    features[\"next.done\"] = Value(dtype=\"bool\", id=None)\n",
    "    features[\"index\"] = Value(dtype=\"int64\", id=None)\n",
    "    features[\"dones\"] = Value(dtype=\"bool\", id=None)\n",
    "    features[\"rewards\"] = Value(dtype=\"float32\", id=None)\n",
    "\n",
    "    hf_dataset = Dataset.from_dict(data_dict, features=Features(features))\n",
    "    hf_dataset.set_transform(hf_transform_to_torch)\n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_robomimic_hdf5(hdf5_path, videos_dir, fps, video, episodes, encoding):\n",
    "    f = h5py.File(hdf5_path, \"r\")\n",
    "    demos = list(f[\"data\"].keys())\n",
    "\n",
    "    lengths=[]\n",
    "    for demo_name in demos:\n",
    "        demo=f['data'][demo_name]\n",
    "        num_samples=demo.attrs['num_samples']\n",
    "        lengths.append(num_samples)\n",
    "\n",
    "    lengths=np.array(lengths)\n",
    "\n",
    "    print('Number of demos: ', len(demos))\n",
    "    print('Max length: ', np.max(lengths))\n",
    "    print('Min length: ', np.min(lengths))\n",
    "    print('Mean length: ', np.mean(lengths))\n",
    "\n",
    "    demo=f['data'][demos[0]]\n",
    "    demo_keys=['actions', 'dones', 'rewards', 'states']\n",
    "    obs_keys = [key for key in demo['obs'].keys()]\n",
    "    obs_keys_images=[key for key in obs_keys if 'image' in key]\n",
    "    obs_keys_others=[key for key in obs_keys if 'image' not in key]\n",
    "\n",
    "    num_episodes=len(demos)\n",
    "     \n",
    "    ep_dicts = []\n",
    "    ep_ids = range(num_episodes)\n",
    "    for ep_idx in tqdm.tqdm(ep_ids):\n",
    "        demo_name=demos[ep_idx]\n",
    "        episode=f['data'][demo_name]\n",
    "        num_frames=episode.attrs['num_samples']  \n",
    "\n",
    "        ep_dict = {} \n",
    "\n",
    "        for key in demo_keys:\n",
    "            ep_dict[key] = torch.from_numpy(episode[key][:])\n",
    "\n",
    "        for key in obs_keys_others:\n",
    "            ep_dict[f\"observation.{key}\"] = torch.from_numpy(episode['obs'][key][:])\n",
    "\n",
    "        ep_dict['observation.state'] = ep_dict['states']\n",
    "        del ep_dict['states']\n",
    "\n",
    "        ep_dict['action']=ep_dict['actions']\n",
    "        del ep_dict['actions']\n",
    "\n",
    "        ep_dict['next.done']=ep_dict['dones']\n",
    "\n",
    "        for key in obs_keys_images:\n",
    "            ep_dict[f\"observation.images.{key}\"] = torch.from_numpy(episode['obs'][key][:])\n",
    "        \n",
    "        ep_dict[\"episode_index\"] = torch.tensor([ep_idx] * num_frames)\n",
    "        ep_dict[\"frame_index\"] = torch.arange(0, num_frames, 1)\n",
    "        ep_dict[\"timestamp\"] = torch.arange(0, num_frames, 1) / fps \n",
    "        # TODO(rcadene): add reward and success by computing them in sim\n",
    "\n",
    "        assert isinstance(ep_idx, int)\n",
    "        ep_dicts.append(ep_dict)\n",
    "    \n",
    "    data_dict = concatenate_episodes(ep_dicts) \n",
    "    total_frames = data_dict[\"frame_index\"].shape[0]\n",
    "    data_dict[\"index\"] = torch.arange(0, total_frames, 1) \n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_robomimic_hdf5_to_lerobot_format(\n",
    "    hdf5_path: Path,\n",
    "    videos_dir: Path,\n",
    "    fps: int | None = None,\n",
    "    video: bool = True,\n",
    "    episodes: list[int] | None = None,\n",
    "    encoding: dict | None = None,\n",
    "): \n",
    "    if fps is None:\n",
    "        fps = 50\n",
    " \n",
    "    data_dict = load_from_robomimic_hdf5(hdf5_path, videos_dir, fps, video, episodes, encoding)\n",
    "    hf_dataset = robomimic_to_hf_dataset(data_dict, video=video)\n",
    "    episode_data_index = calculate_episode_data_index(hf_dataset)\n",
    "    info = {\n",
    "        \"codebase_version\": CODEBASE_VERSION,\n",
    "        \"fps\": fps,\n",
    "        \"video\": video,\n",
    "    }  \n",
    "    return hf_dataset, episode_data_index, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of demos:  40\n",
      "Max length:  63\n",
      "Min length:  38\n",
      "Mean length:  49.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 289.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['dones', 'rewards', 'observation.object', 'observation.robot0_eef_pos', 'observation.robot0_eef_quat', 'observation.robot0_eef_vel_ang', 'observation.robot0_eef_vel_lin', 'observation.robot0_gripper_qpos', 'observation.robot0_gripper_qvel', 'observation.robot0_joint_pos', 'observation.robot0_joint_pos_cos', 'observation.robot0_joint_pos_sin', 'observation.robot0_joint_vel', 'observation.state', 'action', 'next.done', 'observation.images.agentview_image', 'observation.images.robot0_eye_in_hand_image', 'episode_index', 'frame_index', 'timestamp', 'index'],\n",
      "    num_rows: 1992\n",
      "})\n",
      "{'from': tensor([   0,   54,  103,  153,  216,  268,  313,  360,  414,  454,  503,  560,\n",
      "         608,  651,  692,  740,  789,  830,  883,  930,  977, 1021, 1074, 1112,\n",
      "        1159, 1201, 1249, 1297, 1344, 1395, 1446, 1498, 1553, 1610, 1669, 1729,\n",
      "        1779, 1833, 1887, 1942]), 'to': tensor([  54,  103,  153,  216,  268,  313,  360,  414,  454,  503,  560,  608,\n",
      "         651,  692,  740,  789,  830,  883,  930,  977, 1021, 1074, 1112, 1159,\n",
      "        1201, 1249, 1297, 1344, 1395, 1446, 1498, 1553, 1610, 1669, 1729, 1779,\n",
      "        1833, 1887, 1942, 1992])}\n",
      "{'codebase_version': 'v1.6', 'fps': 20, 'video': False}\n"
     ]
    }
   ],
   "source": [
    "hdf5_path = Path(\"/home/ns1254/data_robomimic/nn/lift_image_v141_20p_abs.hdf5\")\n",
    "hf_dataset, episode_data_index, info = from_robomimic_hdf5_to_lerobot_format(hdf5_path, None, 20, False)\n",
    "print(hf_dataset)\n",
    "print(episode_data_index)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=LeRobotDataset.from_preloaded(LeRobotDataset, hf_dataset=hf_dataset, episode_data_index=episode_data_index, info=info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeRobotDataset(\n",
       "  Repository ID: '<class 'lerobot.common.datasets.lerobot_dataset.LeRobotDataset'>',\n",
       "  Split: 'train',\n",
       "  Number of Samples: 1992,\n",
       "  Number of Episodes: 40,\n",
       "  Type: image (.png),\n",
       "  Recorded Frames per Second: 20,\n",
       "  Camera Keys: ['observation.images.agentview_image', 'observation.images.robot0_eye_in_hand_image'],\n",
       "  Video Frame Keys: N/A,\n",
       "  Transformations: None,\n",
       "  Codebase Version: v1.6,\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "average number of frames per episode: 49.800\n",
      "frames per second used during data collection: dataset.fps=20\n",
      "keys to access images from cameras: dataset.camera_keys=['observation.images.agentview_image', 'observation.images.robot0_eye_in_hand_image']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\naverage number of frames per episode: {dataset.num_samples / dataset.num_episodes:.3f}\")\n",
    "print(f\"frames per second used during data collection: {dataset.fps=}\")\n",
    "print(f\"keys to access images from cameras: {dataset.camera_keys=}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.datasets.populate_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1992/1992 [00:00<00:00, 40980.05 examples/s]\n",
      "/home/ns1254/lerobot/lerobot/scripts/push_dataset_to_hub.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  episode_data_index = {key: torch.tensor(episode_data_index[key]) for key in episode_data_index}\n"
     ]
    }
   ],
   "source": [
    "lerobot_dataset=dataset\n",
    "hf_dataset = lerobot_dataset.hf_dataset\n",
    "info = lerobot_dataset.info\n",
    "stats = lerobot_dataset.stats\n",
    "episode_data_index = lerobot_dataset.episode_data_index\n",
    "# local_dir = lerobot_dataset.videos_dir.parent\n",
    "local_dir  = Path(\"/home/ns1254/lerobot/data/lift\")\n",
    "meta_data_dir = local_dir / \"meta_data\"\n",
    "\n",
    "hf_dataset = hf_dataset.with_format(None)  # to remove transforms that cant be saved\n",
    "hf_dataset.save_to_disk(str(local_dir / \"train\"))\n",
    "\n",
    "if stats==None: \n",
    "    stats={}\n",
    "save_meta_data(info, stats, episode_data_index, meta_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
